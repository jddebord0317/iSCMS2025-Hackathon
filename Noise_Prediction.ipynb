!pip -q install pandas numpy scikit-learn joblib pyarrow

# --- Upload train + test CSVs ---
from google.colab import files
print("Please upload your TRAIN file (e.g., train.csv)")
uploaded = files.upload()
TRAIN_CSV = list(uploaded.keys())[0]

print("Please upload your TEST file (e.g., test.csv)")
uploaded_test = files.upload()
TEST_CSV = list(uploaded_test.keys())[0]

# --- Imports & helpers ---
import pandas as pd, numpy as np, joblib
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import average_precision_score, roc_auc_score, precision_recall_curve

FEATURES = ["intensity","snr_local","snr_bg","promin_local","promin_bg",
            "d_left","d_right","curv","peakness"]

def fast_feats(g, half_window=8, bg_half_window=32, eps=1e-9):
    g = g.sort_values("mz").reset_index(drop=True).copy()
    x = g["intensity"].astype(float)
    w, wb = 2*half_window+1, 2*bg_half_window+1

    mu_s  = x.rolling(w,  center=True, min_periods=1).mean()
    sd_s  = x.rolling(w,  center=True, min_periods=1).std(ddof=0).fillna(0.0)
    med_s = x.rolling(w,  center=True, min_periods=1).median()
    mu_bg = x.rolling(wb, center=True, min_periods=1).mean()
    sd_bg = x.rolling(wb, center=True, min_periods=1).std(ddof=0).fillna(0.0)
    med_bg= x.rolling(wb, center=True, min_periods=1).median()

    snr_local    = (x - mu_s)/(sd_s+eps)
    snr_bg       = (x - mu_bg)/(sd_bg+eps)
    promin_local = x - med_s
    promin_bg    = x - med_bg

    d_left  = x.diff().fillna(0.0)
    d_right = (-x.diff(-1)).fillna(0.0)
    curv    = (x.shift(1).fillna(x.iloc[0]) - 2*x + x.shift(-1).fillna(x.iloc[-1]))
    peakness= np.maximum(np.minimum(d_left,0)*np.maximum(d_right,0),0)

    return pd.DataFrame({
        "mz": g["mz"].values,
        "intensity": x.values,
        "snr_local": snr_local.values,
        "snr_bg": snr_bg.values,
        "promin_local": promin_local.values,
        "promin_bg": promin_bg.values,
        "d_left": d_left.values,
        "d_right": d_right.values,
        "curv": curv.values,
        "peakness": np.nan_to_num(peakness.values, nan=0.0, posinf=0.0, neginf=0.0)
    })

# --- Train ---
df = pd.read_csv(TRAIN_CSV)
if "spectrum_id" not in df.columns and "spec_no" in df.columns: 
    df = df.rename(columns={"spec_no":"spectrum_id"})
if "spectrum_id" not in df.columns: 
    df["spectrum_id"] = 0

# Detect label column
label_col = "signal" if "signal" in df.columns else "is_peak"
if label_col not in df.columns:
    raise ValueError(f"No labels found. Expected 'signal' or 'is_peak', got: {df.columns.tolist()}")

feats=[]
for sid,g in df.groupby("spectrum_id",sort=False):
    f=fast_feats(g[["mz","intensity"]]); f.insert(0,"spectrum_id",sid)
    f["is_peak"]=g[label_col].astype(int).values
    feats.append(f)
F=pd.concat(feats,ignore_index=True)
X,y=F[FEATURES].fillna(0.0),F["is_peak"].astype(int).values

pre=ColumnTransformer([("num",StandardScaler(),FEATURES)],remainder="drop")
base=HistGradientBoostingClassifier(max_leaf_nodes=31,learning_rate=0.08,min_samples_leaf=20)
clf=CalibratedClassifierCV(base,cv=3,method="isotonic")
pipe=Pipeline([("pre",pre),("clf",clf)])
pipe.fit(X,y)

proba=pipe.predict_proba(X)[:,1]
ap,roc=average_precision_score(y,proba),roc_auc_score(y,proba)
p,r,t=precision_recall_curve(y,proba); f1=2*p*r/(p+r+1e-12)
thr=float(0.5 if len(t)==0 else t[np.nanargmax(f1)])
print("Training metrics:",{"AP":ap,"ROC_AUC":roc,"best_threshold":thr})

joblib.dump({"model":pipe,"best_threshold":thr},"model.joblib")

# --- Predict on test ---
df_test=pd.read_csv(TEST_CSV)
if "spectrum_id" not in df_test.columns and "spec_no" in df_test.columns: 
    df_test=df_test.rename(columns={"spec_no":"spectrum_id"})
if "spectrum_id" not in df_test.columns: 
    df_test["spectrum_id"]=0

results=[]
for sid,g in df_test.groupby("spectrum_id",sort=False):
    f=fast_feats(g[["mz","intensity"]]); f.insert(0,"spectrum_id",sid)
    X=f[FEATURES].fillna(0.0)
    proba=pipe.predict_proba(X)[:,1]; pred=(proba>=thr).astype(int)
    out=f[["spectrum_id","mz","intensity"]].copy()
    out["peak_prob"]=proba; out["is_peak_pred"]=pred
    results.append(out)
pred_df=pd.concat(results,ignore_index=True)
pred_df.to_csv("test_predictions.csv",index=False)
print("Saved test_predictions.csv")

# --- Download predictions ---
files.download("test_predictions.csv")
